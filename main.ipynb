{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAE Modélisation Mathématique"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MARIE Nathan <br>\n",
    "COUET Benjamin"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages et librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\nust6\\appdata\\roaming\\python\\python311\\site-packages (2.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\nust6\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\nust6\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\nust6\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\nust6\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (1.25.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\nust6\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: tqdm in c:\\users\\nust6\\appdata\\roaming\\python\\python311\\site-packages (4.66.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: colorama in c:\\users\\nust6\\appdata\\roaming\\python\\python311\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: spacy in c:\\users\\nust6\\appdata\\roaming\\python\\python311\\site-packages (3.7.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\nust6\\appdata\\roaming\\python\\python311\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\nust6\\appdata\\roaming\\python\\python311\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\nust6\\appdata\\roaming\\python\\python311\\site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\nust6\\appdata\\roaming\\python\\python311\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\nust6\\appdata\\roaming\\python\\python311\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in c:\\users\\nust6\\appdata\\roaming\\python\\python311\\site-packages (from spacy) (8.2.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\nust6\\appdata\\roaming\\python\\python311\\site-packages (from spacy) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\nust6\\appdata\\roaming\\python\\python311\\site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\nust6\\appdata\\roaming\\python\\python311\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\nust6\\appdata\\roaming\\python\\python311\\site-packages (from spacy) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\nust6\\appdata\\roaming\\python\\python311\\site-packages (from spacy) (0.9.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\nust6\\appdata\\roaming\\python\\python311\\site-packages (from spacy) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\nust6\\appdata\\roaming\\python\\python311\\site-packages (from spacy) (4.66.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\nust6\\appdata\\roaming\\python\\python311\\site-packages (from spacy) (2.28.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\nust6\\appdata\\roaming\\python\\python311\\site-packages (from spacy) (2.5.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\nust6\\appdata\\roaming\\python\\python311\\site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\nust6\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (65.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\nust6\\appdata\\roaming\\python\\python311\\site-packages (from spacy) (23.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\nust6\\appdata\\roaming\\python\\python311\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\nust6\\appdata\\roaming\\python\\python311\\site-packages (from spacy) (1.25.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\nust6\\appdata\\roaming\\python\\python311\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.5 in c:\\users\\nust6\\appdata\\roaming\\python\\python311\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.14.5)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\nust6\\appdata\\roaming\\python\\python311\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nust6\\appdata\\roaming\\python\\python311\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nust6\\appdata\\roaming\\python\\python311\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\nust6\\appdata\\roaming\\python\\python311\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nust6\\appdata\\roaming\\python\\python311\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\nust6\\appdata\\roaming\\python\\python311\\site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\nust6\\appdata\\roaming\\python\\python311\\site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.1.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\nust6\\appdata\\roaming\\python\\python311\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\nust6\\appdata\\roaming\\python\\python311\\site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\nust6\\appdata\\roaming\\python\\python311\\site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\nust6\\appdata\\roaming\\python\\python311\\site-packages (from jinja2->spacy) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python est introuvable. Ex�cutez sans argument pour proc�der � l\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.1/12.8 MB 4.3 MB/s eta 0:00:03\n",
      "      --------------------------------------- 0.3/12.8 MB 4.0 MB/s eta 0:00:04\n",
      "     - -------------------------------------- 0.4/12.8 MB 4.4 MB/s eta 0:00:03\n",
      "     - -------------------------------------- 0.6/12.8 MB 4.2 MB/s eta 0:00:03\n",
      "     -- ------------------------------------- 0.7/12.8 MB 4.3 MB/s eta 0:00:03\n",
      "     -- ------------------------------------- 0.9/12.8 MB 4.2 MB/s eta 0:00:03\n",
      "     --- ------------------------------------ 1.0/12.8 MB 4.2 MB/s eta 0:00:03\n",
      "     --- ------------------------------------ 1.2/12.8 MB 4.1 MB/s eta 0:00:03\n",
      "     ---- ----------------------------------- 1.3/12.8 MB 4.2 MB/s eta 0:00:03\n",
      "     ---- ----------------------------------- 1.4/12.8 MB 4.0 MB/s eta 0:00:03\n",
      "     ----- ---------------------------------- 1.6/12.8 MB 4.1 MB/s eta 0:00:03\n",
      "     ----- ---------------------------------- 1.8/12.8 MB 4.1 MB/s eta 0:00:03\n",
      "     ----- ---------------------------------- 1.9/12.8 MB 4.0 MB/s eta 0:00:03\n",
      "     ------ --------------------------------- 2.0/12.8 MB 4.1 MB/s eta 0:00:03\n",
      "     ------ --------------------------------- 2.2/12.8 MB 4.1 MB/s eta 0:00:03\n",
      "     ------- -------------------------------- 2.3/12.8 MB 4.1 MB/s eta 0:00:03\n",
      "     ------- -------------------------------- 2.5/12.8 MB 4.1 MB/s eta 0:00:03\n",
      "     -------- ------------------------------- 2.6/12.8 MB 4.1 MB/s eta 0:00:03\n",
      "     -------- ------------------------------- 2.8/12.8 MB 4.1 MB/s eta 0:00:03\n",
      "     --------- ------------------------------ 2.9/12.8 MB 4.1 MB/s eta 0:00:03\n",
      "     --------- ------------------------------ 3.1/12.8 MB 4.1 MB/s eta 0:00:03\n",
      "     ---------- ----------------------------- 3.2/12.8 MB 4.1 MB/s eta 0:00:03\n",
      "     ---------- ----------------------------- 3.4/12.8 MB 4.1 MB/s eta 0:00:03\n",
      "     ---------- ----------------------------- 3.5/12.8 MB 4.1 MB/s eta 0:00:03\n",
      "     ----------- ---------------------------- 3.6/12.8 MB 4.1 MB/s eta 0:00:03\n",
      "     ----------- ---------------------------- 3.8/12.8 MB 4.1 MB/s eta 0:00:03\n",
      "     ------------ --------------------------- 3.9/12.8 MB 4.1 MB/s eta 0:00:03\n",
      "     ------------ --------------------------- 4.1/12.8 MB 4.1 MB/s eta 0:00:03\n",
      "     ------------- -------------------------- 4.2/12.8 MB 4.1 MB/s eta 0:00:03\n",
      "     ------------- -------------------------- 4.4/12.8 MB 4.0 MB/s eta 0:00:03\n",
      "     -------------- ------------------------- 4.5/12.8 MB 4.1 MB/s eta 0:00:03\n",
      "     -------------- ------------------------- 4.7/12.8 MB 4.0 MB/s eta 0:00:03\n",
      "     --------------- ------------------------ 4.8/12.8 MB 4.1 MB/s eta 0:00:02\n",
      "     --------------- ------------------------ 5.0/12.8 MB 4.1 MB/s eta 0:00:02\n",
      "     --------------- ------------------------ 5.1/12.8 MB 4.0 MB/s eta 0:00:02\n",
      "     ---------------- ----------------------- 5.3/12.8 MB 4.0 MB/s eta 0:00:02\n",
      "     ---------------- ----------------------- 5.4/12.8 MB 4.0 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.6/12.8 MB 4.0 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.7/12.8 MB 4.0 MB/s eta 0:00:02\n",
      "     ------------------ --------------------- 5.9/12.8 MB 4.1 MB/s eta 0:00:02\n",
      "     ------------------ --------------------- 6.0/12.8 MB 4.0 MB/s eta 0:00:02\n",
      "     ------------------- -------------------- 6.1/12.8 MB 4.0 MB/s eta 0:00:02\n",
      "     ------------------- -------------------- 6.3/12.8 MB 4.1 MB/s eta 0:00:02\n",
      "     -------------------- ------------------- 6.5/12.8 MB 4.0 MB/s eta 0:00:02\n",
      "     -------------------- ------------------- 6.6/12.8 MB 4.0 MB/s eta 0:00:02\n",
      "     --------------------- ------------------ 6.7/12.8 MB 4.1 MB/s eta 0:00:02\n",
      "     --------------------- ------------------ 6.9/12.8 MB 4.0 MB/s eta 0:00:02\n",
      "     --------------------- ------------------ 7.0/12.8 MB 4.1 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 7.2/12.8 MB 4.1 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 7.3/12.8 MB 4.1 MB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 7.5/12.8 MB 4.0 MB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 7.6/12.8 MB 4.1 MB/s eta 0:00:02\n",
      "     ------------------------ --------------- 7.8/12.8 MB 4.1 MB/s eta 0:00:02\n",
      "     ------------------------ --------------- 7.9/12.8 MB 4.1 MB/s eta 0:00:02\n",
      "     ------------------------- -------------- 8.1/12.8 MB 4.1 MB/s eta 0:00:02\n",
      "     ------------------------- -------------- 8.2/12.8 MB 4.1 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 8.4/12.8 MB 4.0 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 8.5/12.8 MB 4.1 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 8.7/12.8 MB 4.1 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 8.8/12.8 MB 4.1 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 8.9/12.8 MB 4.1 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 9.1/12.8 MB 4.1 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 9.3/12.8 MB 4.1 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 9.4/12.8 MB 4.1 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 9.6/12.8 MB 4.0 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 9.7/12.8 MB 4.1 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 9.9/12.8 MB 4.1 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 10.0/12.8 MB 4.1 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 10.2/12.8 MB 4.1 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 10.3/12.8 MB 4.0 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 10.5/12.8 MB 4.1 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 10.6/12.8 MB 4.1 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 10.8/12.8 MB 4.1 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 10.9/12.8 MB 4.1 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 11.1/12.8 MB 4.1 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 11.2/12.8 MB 4.1 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 11.4/12.8 MB 4.1 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 11.5/12.8 MB 4.1 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 11.7/12.8 MB 4.1 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 11.8/12.8 MB 4.1 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 12.0/12.8 MB 4.1 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 12.1/12.8 MB 4.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 12.3/12.8 MB 4.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 12.5/12.8 MB 4.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.6/12.8 MB 4.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.7/12.8 MB 4.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.8/12.8 MB 4.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.8/12.8 MB 4.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.2 in c:\\users\\nust6\\appdata\\roaming\\python\\python311\\site-packages (from en-core-web-sm==3.7.1) (3.7.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\nust6\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\nust6\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\nust6\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\nust6\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\nust6\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in c:\\users\\nust6\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\nust6\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\nust6\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\nust6\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\nust6\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\nust6\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\nust6\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\nust6\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\nust6\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.28.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\nust6\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.5.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\nust6\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\nust6\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (65.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\nust6\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (23.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\nust6\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\nust6\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.25.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\nust6\\appdata\\roaming\\python\\python311\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.5 in c:\\users\\nust6\\appdata\\roaming\\python\\python311\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.14.5)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\nust6\\appdata\\roaming\\python\\python311\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nust6\\appdata\\roaming\\python\\python311\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nust6\\appdata\\roaming\\python\\python311\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\nust6\\appdata\\roaming\\python\\python311\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nust6\\appdata\\roaming\\python\\python311\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2022.12.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\nust6\\appdata\\roaming\\python\\python311\\site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\nust6\\appdata\\roaming\\python\\python311\\site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\nust6\\appdata\\roaming\\python\\python311\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\nust6\\appdata\\roaming\\python\\python311\\site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\nust6\\appdata\\roaming\\python\\python311\\site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\nust6\\appdata\\roaming\\python\\python311\\site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.3)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\nust6\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.3.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in c:\\users\\nust6\\appdata\\roaming\\python\\python311\\site-packages (from scikit-learn) (1.25.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\nust6\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\nust6\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\nust6\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (3.2.0)\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas\n",
    "%pip install tqdm\n",
    "%pip install spacy\n",
    "!python3 -m spacy download en_core_web_sm\n",
    "!python -m spacy download en_core_web_sm\n",
    "%pip install scikit-learn\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import gzip\n",
    "from tqdm import tqdm\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import spacy\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition des variables globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOLD = '\\033[1m' # ACTIONS\n",
    "BLUE = '\\033[94m' # ACTIONSv\n",
    "RESET = '\\033[0m'\n",
    "RED = '\\033[91m' # ERRORS\n",
    "GREEN = '\\033[92m' # SUCCESS\n",
    "YELLOW = '\\033[93m' # INFORMATIONS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nettoyage des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traitementData():\n",
    "    print(BOLD+BLUE+\"\\n\\nChargement des données...\\n\\n\")\n",
    "    \n",
    "    def parse(path):\n",
    "        g = gzip.open(path, 'rb')\n",
    "        for l in g:\n",
    "            yield json.loads(l)\n",
    "            \n",
    "    def getDF(path):\n",
    "        i = 0\n",
    "        df = {}\n",
    "        for d in parse(path):\n",
    "            df[i] = d\n",
    "            i += 1\n",
    "        return pd.DataFrame.from_dict(df, orient='index')\n",
    "    \n",
    "    df = getDF(\"./data/Video_Games.json.gz\")\n",
    "    \n",
    "    df = df.drop(['style', 'image'], axis=1)\n",
    "    \n",
    "    df=df.dropna(subset=[\"reviewText\"])\n",
    "\n",
    "    df['vote'] = df['vote'].fillna(0.0)\n",
    "\n",
    "    if not df['reviewText'].notna().all():\n",
    "        print(RED+\"Certains reviewText sont null\\n\")\n",
    "    else:\n",
    "        print(GREEN+\"Aucun reviewText null\\n\")\n",
    "\n",
    "    df['reviewTime'] = pd.to_datetime(df['reviewTime'], format='%m %d, %Y')\n",
    "\n",
    "    df['year'] = df['reviewTime'].dt.year\n",
    "\n",
    "    os.makedirs('./split_data', exist_ok=True)\n",
    "\n",
    "    for year, group in df.groupby('year'):\n",
    "        if not os.path.exists(f'./split_data/reviews_{year}.json'):\n",
    "            group.to_json(f'./split_data/reviews_{year}.json', orient='records', lines=True)\n",
    "            print(GREEN + f'Fichier JSON créé pour l\\'année {year}' + RESET)\n",
    "        else:\n",
    "            print(GREEN + f'Fichier JSON pour l\\'année {year} existe déjà !' + RESET)\n",
    "        \n",
    "        group=group.drop_duplicates(subset=[\"asin\",\"reviewerID\",\"vote\"], keep='last', inplace=True)\n",
    "        if group!=None:\n",
    "            print(f\"{RED}Problème de doublons sur : {group}\")\n",
    "        else:\n",
    "            print(f\"{YELLOW}PAS DE DOUBLONS\")\n",
    "\n",
    "\n",
    "    print(BLUE+'*\\n\\n'+RESET+BOLD+\"Dimensions du DataFrame => \"+YELLOW+f\"{df.shape}\" + RESET)\n",
    "    print(BOLD+\"\\nColonnes => \"+YELLOW+f\"{df.columns.to_list()}\"+RESET)\n",
    "    print(BOLD+\"\\nNombre de textes d'avis null => \"+YELLOW+f\"{df['reviewText'].isnull().sum()}\"+RESET)\n",
    "    print(BOLD+\"\\nNombre de titres d'avis null => \"+YELLOW+f\"{df['summary'].isnull().sum()}\"+RESET)\n",
    "    print(BOLD+\"\\nNombre de notes null => \"+YELLOW+f\"{df['overall'].isnull().sum()}\"+RESET)\n",
    "    print(BOLD+\"\\nNombre de votes null => \"+YELLOW+f\"{df['vote'].isnull().sum()}\"+RESET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[94m\n",
      "\n",
      "Chargement des données...\n",
      "\n",
      "\n",
      "\u001b[92mAucun reviewText null\n",
      "\n",
      "\u001b[92mFichier JSON pour l'année 1997 existe déjà !\u001b[0m\n",
      "\u001b[93mPAS DE DOUBLONS\n",
      "\u001b[92mFichier JSON pour l'année 1998 existe déjà !\u001b[0m\n",
      "\u001b[93mPAS DE DOUBLONS\n",
      "\u001b[92mFichier JSON pour l'année 1999 existe déjà !\u001b[0m\n",
      "\u001b[93mPAS DE DOUBLONS\n",
      "\u001b[92mFichier JSON pour l'année 2000 existe déjà !\u001b[0m\n",
      "\u001b[93mPAS DE DOUBLONS\n",
      "\u001b[92mFichier JSON pour l'année 2001 existe déjà !\u001b[0m\n",
      "\u001b[93mPAS DE DOUBLONS\n",
      "\u001b[92mFichier JSON pour l'année 2002 existe déjà !\u001b[0m\n",
      "\u001b[93mPAS DE DOUBLONS\n",
      "\u001b[92mFichier JSON pour l'année 2003 existe déjà !\u001b[0m\n",
      "\u001b[93mPAS DE DOUBLONS\n",
      "\u001b[92mFichier JSON pour l'année 2004 existe déjà !\u001b[0m\n",
      "\u001b[93mPAS DE DOUBLONS\n",
      "\u001b[92mFichier JSON pour l'année 2005 existe déjà !\u001b[0m\n",
      "\u001b[93mPAS DE DOUBLONS\n",
      "\u001b[92mFichier JSON pour l'année 2006 existe déjà !\u001b[0m\n",
      "\u001b[93mPAS DE DOUBLONS\n",
      "\u001b[92mFichier JSON pour l'année 2007 existe déjà !\u001b[0m\n",
      "\u001b[93mPAS DE DOUBLONS\n",
      "\u001b[92mFichier JSON pour l'année 2008 existe déjà !\u001b[0m\n",
      "\u001b[93mPAS DE DOUBLONS\n",
      "\u001b[92mFichier JSON pour l'année 2009 existe déjà !\u001b[0m\n",
      "\u001b[93mPAS DE DOUBLONS\n",
      "\u001b[92mFichier JSON pour l'année 2010 existe déjà !\u001b[0m\n",
      "\u001b[93mPAS DE DOUBLONS\n",
      "\u001b[92mFichier JSON pour l'année 2011 existe déjà !\u001b[0m\n",
      "\u001b[93mPAS DE DOUBLONS\n",
      "\u001b[92mFichier JSON pour l'année 2012 existe déjà !\u001b[0m\n",
      "\u001b[93mPAS DE DOUBLONS\n",
      "\u001b[92mFichier JSON pour l'année 2013 existe déjà !\u001b[0m\n",
      "\u001b[93mPAS DE DOUBLONS\n",
      "\u001b[92mFichier JSON pour l'année 2014 existe déjà !\u001b[0m\n",
      "\u001b[93mPAS DE DOUBLONS\n",
      "\u001b[92mFichier JSON pour l'année 2015 existe déjà !\u001b[0m\n",
      "\u001b[93mPAS DE DOUBLONS\n",
      "\u001b[92mFichier JSON pour l'année 2016 existe déjà !\u001b[0m\n",
      "\u001b[93mPAS DE DOUBLONS\n",
      "\u001b[92mFichier JSON pour l'année 2017 existe déjà !\u001b[0m\n",
      "\u001b[93mPAS DE DOUBLONS\n",
      "\u001b[92mFichier JSON pour l'année 2018 existe déjà !\u001b[0m\n",
      "\u001b[93mPAS DE DOUBLONS\n",
      "\u001b[94m*\n",
      "\n",
      "\u001b[0m\u001b[1mDimensions du DataFrame => \u001b[93m(2563634, 12)\u001b[0m\n",
      "\u001b[1m\n",
      "Colonnes => \u001b[93m['overall', 'verified', 'reviewTime', 'reviewerID', 'asin', 'reviewerName', 'reviewText', 'summary', 'unixReviewTime', 'vote', 'label', 'year']\u001b[0m\n",
      "\u001b[1m\n",
      "Nombre de textes d'avis null => \u001b[93m0\u001b[0m\n",
      "\u001b[1m\n",
      "Nombre de titres d'avis null => \u001b[93m748\u001b[0m\n",
      "\u001b[1m\n",
      "Nombre de notes null => \u001b[93m0\u001b[0m\n",
      "\u001b[1m\n",
      "Nombre de votes null => \u001b[93m0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "traitementData()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sélection du jeu de données à utiliser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_json('./split_data/reviews_2000.json', lines=True)\n",
    "df = df[df['reviewText'] != '']\n",
    "\n",
    "df['label'] = df['overall'].apply(lambda x: 1 if x > 3 else 0) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traitement linguistique avec Spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prétraitement des textes:   0%|          | 0/9963 [03:29<?, ?it/s]\n",
      "Prétraitement des textes: 100%|██████████| 9963/9963 [01:57<00:00, 85.03it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\n",
      "Traitement liguistique réussi\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "t = tqdm(total=df.shape[0], desc=\"Prétraitement des textes\")\n",
    "\n",
    "\n",
    "def preprocess(text):\n",
    "    return [' '.join([token.lemma_ for token in doc if not token.is_stop and not token.is_punct]) \n",
    "            for doc in tqdm(nlp.pipe(text, batch_size=50    ), total=len(text), desc=\"Prétraitement des textes\")]\n",
    "\n",
    "def traitementLinguistique(): \n",
    "    #print(BOLD+BLUE+\"\\n\\nTraitement linguistique...\\n\\n*\")\n",
    "    try:\n",
    "        df['processed_text'] = preprocess(df['reviewText'].tolist())\n",
    "        print(GREEN+\"\\nTraitement liguistique réussi\"+RESET)\n",
    "    except Exception as e:\n",
    "        print(RED+\"\\nErreur lors du traitement linguistique => \"+RESET+YELLOW+f\"{e}\"+RESET)\n",
    "\n",
    "traitementLinguistique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifieur Binaire"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorisation des commentaires\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'label'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'label'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[106], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m vector \u001b[38;5;241m=\u001b[39m CountVectorizer()\n\u001b[0;32m      2\u001b[0m X \u001b[38;5;241m=\u001b[39m vector\u001b[38;5;241m.\u001b[39mfit_transform(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprocessed_text\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m----> 3\u001b[0m Y \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(YELLOW\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVECTOR SHAPE : \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mRESET\u001b[38;5;241m+\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'label'"
     ]
    }
   ],
   "source": [
    "vector = CountVectorizer()\n",
    "X = vector.fit_transform(df['processed_text'])\n",
    "Y = df['label']\n",
    "print(YELLOW+\"VECTOR SHAPE : \"+RESET+f\"{X.shape}\")\n",
    "\n",
    "try:\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "    print(GREEN+\"Données splittées avec succès\"+RESET)\n",
    "except:\n",
    "    print(RED+\"Erreur lors du split des données\"+RESET)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création du classifieur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(BLUE+\"Création du modèle KNN...\"+RESET)\n",
    "try:\n",
    "    knn = KNeighborsClassifier()\n",
    "    knnSearch = GridSearchCV(knn, {'n_neighbors': [3, 5, 7, 9]})\n",
    "    knnSearch.fit(X_train, Y_train)\n",
    "    print(GREEN+\"Modèle KNN créé avec succès\"+RESET)\n",
    "except:\n",
    "    print(RED+\"Erreur lors de la création du modèle KNN\"+RESET)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Évaluation du classifieur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = knnSearch.predict(X_test)\n",
    "print(YELLOW+\"Résultats du modèle KNN :\"+RESET)\n",
    "print(classification_report(Y_test, predictions))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test du classifieur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = knnSearch.predict(vector.transform(preprocess([\"I think I've already written a review for this, but I wanted to add that the engine is much improved over the origanal.  In the first unreal I got an average of 10-20 fps DURING gameplay and 50 or so max (not using timedemo 1 during intro) and in UT I get 40-60+ average and even 100+ max.  This game has been so incredebly improved that I get higher frame rates  with better graphics!\"])))\n",
    "test2 = knnSearch.predict(vector.transform(preprocess(['I love this game !'])))\n",
    "test3 = knnSearch.predict(vector.transform(preprocess([\"Where to begin?  How about...not fun.  Bad graphics+bad gameplay+bad sound+no replay value=bad game.  The saddest part is that Eidos put so much money into this game that good studios (i.e. Looking Glass) ended up  shutting down.  Quake II is still more fun than this!  They should have  pulled the plug on Ion Storm a long time ago.\"])))\n",
    "\n",
    "print(BLUE+\"Test du modèle KNN :\"+RESET)\n",
    "print(YELLOW+f\"test1 (expected 1) : {test1}\")\n",
    "print(f\"test2 (expected 1) : {test2}\")\n",
    "print(f\"test3 (expected 0) : {test3}\"+RESET)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifieur Multiclasses"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorisation des commentaires\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = CountVectorizer()\n",
    "X = vector.fit_transform(df['processed_text'])\n",
    "Y = df['overall']\n",
    "print(YELLOW+\"VECTOR SHAPE : \"+RESET+f\"{X.shape}\")\n",
    "\n",
    "try:\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "    print(GREEN+\"Données splittées avec succès\"+RESET)\n",
    "except:\n",
    "    print(RED+\"Erreur lors du split des données\"+RESET)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création du classifieur multiclasse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(BLUE+\"Création du modèle KNN multiclasse...\"+RESET)\n",
    "try:\n",
    "    knnMulti = KNeighborsClassifier()\n",
    "    knnSearchMulti = GridSearchCV(knnMulti, {'n_neighbors': [3, 5, 7, 9]})\n",
    "    knnSearchMulti.fit(X_train, Y_train)\n",
    "    print(GREEN+\"Modèle KNN multiclasse créé avec succès\"+RESET)\n",
    "except:\n",
    "    print(RED+\"Erreur lors de la création du modèle KNN multiclasse\"+RESET)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Évaluation du classifieur multiclasse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = knnSearchMulti.predict(vector.transform(preprocess([\"I think I've already written a review for this, but I wanted to add that the engine is much improved over the origanal.  In the first unreal I got an average of 10-20 fps DURING gameplay and 50 or so max (not using timedemo 1 during intro) and in UT I get 40-60+ average and even 100+ max.  This game has been so incredebly improved that I get higher frame rates  with better graphics!\"])))\n",
    "test2 = knnSearchMulti.predict(vector.transform(preprocess([\"Where to begin?  How about...not fun.  Bad graphics+bad gameplay+bad sound+no replay value=bad game.  The saddest part is that Eidos put so much money into this game that good studios (i.e. Looking Glass) ended up  shutting down.  Quake II is still more fun than this!  They should have  pulled the plug on Ion Storm a long time ago.\"])))\n",
    "test6 = knnSearchMulti.predict(vector.transform(preprocess([\"Well we all now think that the DreamCast has the best game, it's the best there is in the market, and it beats PS2. Well that may be true. Even though I don't have DC, but looking at the records, did to the Sega fans I doubt DreamCast would become the best out in the market. If you remember to the older versions of Sega, what happened to their games? Yup all gone, they don't send anymore to the US evem before the DC came out, most people may have even forgot there was a Sega company. For those people who has\\/had Sega Saturn would know, it came out with many title of games and the next two years what happened to those games, well they stopped manufacturing them. Also what happend to the Sega Genesis console games??? Well same thing happened, they just stopped shipments. I dunno to much about history but so far I know one thing, history always repeats but in a different way, this time Sega's \\\"best console\\\" will just as well do the same thing like what it did in the past. They just stopped making the games. Well personally if your going to buy any console, I think that you should buy PS2 or wait for the X-Box, but not the next Ninetendo product (Dolphin) because they just don't make good games. Although I must admit Dreamcast does have good graphics. I also think that people who say the graphics of DC is better then PS2, I think they're just to weak to admit the two systems's graphics has no difference.\"])))\n",
    "\n",
    "print(BLUE+\"Test du modèle KNN multiclasses :\"+RESET)\n",
    "print(YELLOW+f\"test1 (expected 5) : {test1}\")\n",
    "print(f\"test2 (expected 1) : {test2}\")\n",
    "print(f\"test3 (expected 1) : {test6}\"+RESET)\n",
    "predictions = knnSearchMulti.predict(X_test)\n",
    "print(YELLOW+\"Résultats du modèle KNN multiclasse :\"+RESET)\n",
    "print(classification_report(Y_test, predictions))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Classifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création du classifieur gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(BLUE+\"Création du modèle GB_Classifier...\"+RESET)\n",
    "try:\n",
    "    GB_Classifier = GradientBoostingClassifier()\n",
    "    GB_Classifier.fit(X_train, Y_train)\n",
    "    print(GREEN+\"Modèle GB_Classifier créé avec succès\"+RESET)\n",
    "except:\n",
    "    print(RED+\"Erreur lors de la création du modèle GB_Classifier\"+RESET)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Évaluation du classifieur multiclasse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = GB_Classifier.predict(vector.transform(preprocess([\"I think I've already written a review for this, but I wanted to add that the engine is much improved over the origanal.  In the first unreal I got an average of 10-20 fps DURING gameplay and 50 or so max (not using timedemo 1 during intro) and in UT I get 40-60+ average and even 100+ max.  This game has been so incredebly improved that I get higher frame rates  with better graphics!\"])))\n",
    "test2 = GB_Classifier.predict(vector.transform(preprocess([\"Where to begin?  How about...not fun.  Bad graphics+bad gameplay+bad sound+no replay value=bad game.  The saddest part is that Eidos put so much money into this game that good studios (i.e. Looking Glass) ended up  shutting down.  Quake II is still more fun than this!  They should have  pulled the plug on Ion Storm a long time ago.\"])))\n",
    "test6 = GB_Classifier.predict(vector.transform(preprocess([\"Well we all now think that the DreamCast has the best game, it's the best there is in the market, and it beats PS2. Well that may be true. Even though I don't have DC, but looking at the records, did to the Sega fans I doubt DreamCast would become the best out in the market. If you remember to the older versions of Sega, what happened to their games? Yup all gone, they don't send anymore to the US evem before the DC came out, most people may have even forgot there was a Sega company. For those people who has\\/had Sega Saturn would know, it came out with many title of games and the next two years what happened to those games, well they stopped manufacturing them. Also what happend to the Sega Genesis console games??? Well same thing happened, they just stopped shipments. I dunno to much about history but so far I know one thing, history always repeats but in a different way, this time Sega's \\\"best console\\\" will just as well do the same thing like what it did in the past. They just stopped making the games. Well personally if your going to buy any console, I think that you should buy PS2 or wait for the X-Box, but not the next Ninetendo product (Dolphin) because they just don't make good games. Although I must admit Dreamcast does have good graphics. I also think that people who say the graphics of DC is better then PS2, I think they're just to weak to admit the two systems's graphics has no difference.\"])))\n",
    "\n",
    "print(BLUE+\"Test du modèle GB :\"+RESET)\n",
    "print(YELLOW+f\"test1 (expected 5) : {test1}\")\n",
    "print(f\"test2 (expected 1) : {test2}\")\n",
    "print(f\"test3 (expected 1) : {test6}\"+RESET)\n",
    "predictions = GB_Classifier.predict(X_test)\n",
    "print(YELLOW+\"Résultats du modèle GB :\"+RESET)\n",
    "print(classification_report(Y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création du classifieur random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(BLUE+\"Création du modèle GB_Classifier...\"+RESET)\n",
    "try:\n",
    "    RD_Classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    RD_Classifier.fit(X_train, Y_train)\n",
    "    print(GREEN+\"Modèle RD_Classifier créé avec succès\"+RESET)\n",
    "except:\n",
    "    print(RED+\"Erreur lors de la création du modèle RD_Classifier\"+RESET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Évaluation du classifieur multiclasse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = RD_Classifier.predict(vector.transform(preprocess([\"I think I've already written a review for this, but I wanted to add that the engine is much improved over the origanal.  In the first unreal I got an average of 10-20 fps DURING gameplay and 50 or so max (not using timedemo 1 during intro) and in UT I get 40-60+ average and even 100+ max.  This game has been so incredebly improved that I get higher frame rates  with better graphics!\"])))\n",
    "test2 = RD_Classifier.predict(vector.transform(preprocess([\"Where to begin?  How about...not fun.  Bad graphics+bad gameplay+bad sound+no replay value=bad game.  The saddest part is that Eidos put so much money into this game that good studios (i.e. Looking Glass) ended up  shutting down.  Quake II is still more fun than this!  They should have  pulled the plug on Ion Storm a long time ago.\"])))\n",
    "test6 = RD_Classifier.predict(vector.transform(preprocess([\"Well we all now think that the DreamCast has the best game, it's the best there is in the market, and it beats PS2. Well that may be true. Even though I don't have DC, but looking at the records, did to the Sega fans I doubt DreamCast would become the best out in the market. If you remember to the older versions of Sega, what happened to their games? Yup all gone, they don't send anymore to the US evem before the DC came out, most people may have even forgot there was a Sega company. For those people who has\\/had Sega Saturn would know, it came out with many title of games and the next two years what happened to those games, well they stopped manufacturing them. Also what happend to the Sega Genesis console games??? Well same thing happened, they just stopped shipments. I dunno to much about history but so far I know one thing, history always repeats but in a different way, this time Sega's \\\"best console\\\" will just as well do the same thing like what it did in the past. They just stopped making the games. Well personally if your going to buy any console, I think that you should buy PS2 or wait for the X-Box, but not the next Ninetendo product (Dolphin) because they just don't make good games. Although I must admit Dreamcast does have good graphics. I also think that people who say the graphics of DC is better then PS2, I think they're just to weak to admit the two systems's graphics has no difference.\"])))\n",
    "\n",
    "print(BLUE+\"Test du modèle GB :\"+RESET)\n",
    "print(YELLOW+f\"test1 (expected 5) : {test1}\")\n",
    "print(f\"test2 (expected 1) : {test2}\")\n",
    "print(f\"test3 (expected 1) : {test6}\"+RESET)\n",
    "predictions = RD_Classifier.predict(X_test)\n",
    "print(YELLOW+\"Résultats du modèle Random forest :\"+RESET)\n",
    "print(classification_report(Y_test, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
